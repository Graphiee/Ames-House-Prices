{
  "cells": [
    {
      "metadata": {
        "_uuid": "42a5bad6806329423bd5615ae34dc2b0add1f074"
      },
      "cell_type": "markdown",
      "source": "First of all we're going to analyse each variable one by one and conduct mind experiment of whether any dependencies between y and x exist. Also we're going to note some potential ideas about feature engineering. But firstly let's check how many missing data do we have."
    },
    {
      "metadata": {
        "_uuid": "1cdc085b9ceaf202784ea653cd2354119eeb90a7",
        "lines_to_next_cell": 2,
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.axes import Axes\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.stattools import kpss\nimport scipy.stats\nfrom scipy.stats import spearmanr\nfrom scipy.stats import ks_2samp\nimport itertools\nfrom itertools import combinations\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.feature_selection import RFE\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import f_classif\nfrom scipy.stats import mannwhitneyu\nimport sys\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.model_selection import cross_validate\nfrom sklearn import metrics   #Additional scklearn functions\nfrom sklearn.model_selection import GridSearchCV   #Perforing grid search\n\npd.set_option('display.max_rows', 100)\npd.set_option('display.max_columns', 100)\ntrain_set=pd.read_csv(r'../input/train.csv')\ntrain=train_set.drop('SalePrice',axis=1).drop('Id',axis=1)\n\ny_train=train_set.SalePrice\ntest_set=pd.read_csv(r'../input/test.csv').drop('Id',axis=1)\n#NAs=train_set.isnull().sum()\n#NAs[NAs!=0]\n\ntrain_test = pd.concat([train_set,test_set],axis=0).reset_index(drop=True)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b3bb20a704a193e665d954aff13a303e9ea236ee"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7bc2628d7b3013b6314fd3b93ed28e1e80d8ca7f"
      },
      "cell_type": "markdown",
      "source": "Nominal data = ['MSSubClass','MSZoning','LotShape','LandContour','LotConfig','LandSlope','Neighborhood','Condition1','Condition2',\n               'BldgType','HouseStyle','YearBuilt','YearRemodAdd','RoofStylec','RoofStyle','RoofMatl', 'Exterior1st','Exterior2nd',\n               'MasVnrType','Foundation', 'Heating', 'Electrical','GarageYrBlt','MiscFeature','MoSold','YrSold','SaleType', 'SaleCondition']\n\nOrdinal data = ['Street','Alley','Utilities','OverallQual','OverallCond','ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure',\n               'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'CentralAir','KitchenQual', 'FireplaceQu','GarageType','GarageFinish',\n               'GarageQual','GarageCond','PavedDrive','PoolQuality','Fence']\n\nInterval data = ['SalePrice','LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF', '1stFlrSF',\n                'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath','FullBath','HalfBath','Bedroom','Kitchen','TotRmsAbvGrd',\n                'Fireplaces', 'GarageCars', 'GarageArea','WoodDeckSF','OpenPorchSF', 'EnclosedPorchSF', '3SsnPorch', 'ScreenPorch', \n                'PoolArea','MiscVal']\n\nComments:\na) LandSlope may be ordinal due to harder building conditions on slope terrain\n\nb) LandContour may be similar variable to LandSlope both to categorazation as well as thing that they descriebe\nc) Condition 1 and 2 might be ordinal if you investigate them more perciselly. Overall they are the same\n\nd) HouseStyle might be ordinal but it is neccasary to understand deeper what split foyer and split level is. I concider even\ncreating separate variable for them if i place that variable as ordinal\n\ne) Exterior1st and Exterior2nd descriebes same thing. You may connect them somehow\n\ng) ExternalQuality and ExternalCond sounds like they descriebe same thing. How something might be good quality if it has bad condition?\n\nh) Same with Overall\n\ni) Same with basement\n\ng) TotalBsmtSF=BsmtFinSF1 + BsmtFinSF2 + BsmtUnfSF\n\nh) Also, BsmtFinType1 and 2 descriebe same thing (like Ext in e point)\n\ni) GrLivArea= 1stFlrSF + 2stFlrSF \n\nj) Connect BsmtFullBath with BsmtHalfBath\n\nk) TotRmsAbvGrd not necassary, because we have split on paticular rooms ?\n\nl) GarageType you may consider it as nominal or not\n\nm) If garage exist and garage year built is not added, then assume that garage year built is house year built\n\nn) GarageQual and Garage cond as h and i point\n\no) May concider merging Porch variables\n\np) Fence may also be nominal"
    },
    {
      "metadata": {
        "_uuid": "0832b52ab3a236efaa9fdc86ea6b273faaa75f79",
        "trusted": true
      },
      "cell_type": "code",
      "source": "fig, axarr = plt.subplots(1,2,figsize=(17,7))\nsns.distplot(train_set.SalePrice,ax=axarr[0])\nscipy.stats.probplot(train_set.SalePrice, plot=plt)\nprint('Skewness=',scipy.stats.skew(train_set.SalePrice))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "64c5e262d4ab27d0d84fb77b2e6b57b37c9b313e"
      },
      "cell_type": "markdown",
      "source": "We're going to deal with this skewness later on. Now we will check distriution of NANs between test and train.\n\n"
    },
    {
      "metadata": {
        "_uuid": "f133dff9582350c8460f1f216e3dfedf4488708a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# fig, axarr = plt.subplots(1,2,figsize=(17,7))\n# for i, missing in enumerate([train_set,test_set]):\n#     missing_1 = missing.isnull().sum()\n#     missing_1[missing_1!=0].sort_values(ascending=False).plot.bar(ax=axarr[i])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9a43575449b5b6bf1c374de74e43929037c79982"
      },
      "cell_type": "markdown",
      "source": "We're going to fill NAs right now."
    },
    {
      "metadata": {
        "_uuid": "07d289dad65a3da6b8ccea1e6514efae892125fe",
        "trusted": true
      },
      "cell_type": "code",
      "source": "missing_1 = train_test.isnull().sum()\nprint(missing_1[missing_1!=0].sort_values(ascending=False).rename('Train missing'))\n\n'''missing_1 = test_set.isnull().sum()\nprint(missing_1[missing_1!=0].sort_values(ascending=False).rename('Test missing'))'''",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "671b58d4feda97e8017187baddbfad68a7a00f8e",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_test =train_test.replace({'MSSubClass':{\n        20:'1-STORY 1946 & NEWER ALL STYLES',\n        30:'1-STORY 1945 & OLDER',\n        40:'1-STORY W/FINISHED ATTIC ALL AGES',\n        45:'1-1/2 STORY - UNFINISHED ALL AGES',\n        50:'1-1/2 STORY FINISHED ALL AGES',\n        60:'2-STORY 1946 & NEWER',\n        70:'2-STORY 1945 & OLDER',\n        75:'2-1/2 STORY ALL AGES',\n        80:'SPLIT OR MULTI-LEVEL',\n        85:'SPLIT FOYER',\n        90:'DUPLEX - ALL STYLES AND AGES',\n       120:'1-STORY PUD (Planned Unit Development) - 1946 & NEWER',\n       150:'1-1/2 STORY PUD - ALL AGES',\n       160:'2-STORY PUD - 1946 & NEWER',\n       180:'PUD - MULTILEVEL - INCL SPLIT LEV/FOYER',\n       190:'2 FAMILY CONVERSION - ALL STYLES AND AGES'}})\n\n'''test_set =test_set.replace({'MSSubClass':{\n        20:'1-STORY 1946 & NEWER ALL STYLES',\n        30:'1-STORY 1945 & OLDER',\n        40:'1-STORY W/FINISHED ATTIC ALL AGES',\n        45:'1-1/2 STORY - UNFINISHED ALL AGES',\n        50:'1-1/2 STORY FINISHED ALL AGES',\n        60:'2-STORY 1946 & NEWER',\n        70:'2-STORY 1945 & OLDER',\n        75:'2-1/2 STORY ALL AGES',\n        80:'SPLIT OR MULTI-LEVEL',\n        85:'SPLIT FOYER',\n        90:'DUPLEX - ALL STYLES AND AGES',\n       120:'1-STORY PUD (Planned Unit Development) - 1946 & NEWER',\n       150:'1-1/2 STORY PUD - ALL AGES',\n       160:'2-STORY PUD - 1946 & NEWER',\n       180:'PUD - MULTILEVEL - INCL SPLIT LEV/FOYER',\n       190:'2 FAMILY CONVERSION - ALL STYLES AND AGES'}})'''\n\n\ntrain_test['MiscFeature'] = train_test['MiscFeature'].fillna('No_misc')\ntrain_test['MasVnrType'] = train_test['MasVnrType'].fillna('None')\n\ntrain_test.MiscFeature.loc[train_test[(train_test.MiscFeature=='No_misc') & (train_test.MiscVal>0)].index] = 'Othr'\ntrain_test.MiscVal.loc[train_test[(train_test.MiscFeature=='Shed') & (train_test.MiscVal==0)].index] = 500\ntrain_test.MiscFeature[(train_test.MiscFeature=='Othr') & (train_test.MiscVal==0)] = 'No_misc'\n\ntrain_test['PoolQC'] = train_test['PoolQC'].fillna('No_pool')\ntrain_test = train_test.replace({'PoolQC':{'Ex':4,'Gd':3,'TA':2,'Fa':1,'No_pool':0}})\n\ntrain_test.PoolQC.loc[[2420,2503,2599]] = 3\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "36b25754a206064fa8294f859d066c50a13f6325"
      },
      "cell_type": "code",
      "source": "train_test['Alley'] = train_test['Alley'].fillna('Doesnt_exist')\ntrain_test['Fence'] = train_test['Fence'].fillna('Doesnt_exist')\ntrain_test['FireplaceQu'] = train_test['FireplaceQu'].fillna(0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bc68d222facae92bf2fbec39633bdb5940cee639"
      },
      "cell_type": "code",
      "source": "garage = ['GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond']\n\ntrain_test['GarageYrBlt'].loc[2576] = 1923\ntrain_test['GarageYrBlt'].loc[2126] = 1910\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e1c182f2bc42831c2eb6cb47575d160c3d7419b8"
      },
      "cell_type": "code",
      "source": "# fig, axarr = plt.subplots(1,2,figsize=(14,7))\n# sns.scatterplot(x='GarageYrBlt',y='YearBuilt',data=train_test,ax=axarr[0])\n# sns.scatterplot(x='GarageYrBlt',y='YearRemodAdd',data=train_test,ax=axarr[1])\n\n# #YearBuilt \tYearRemodAdd",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "79f14996ce48a181008df2c70e0d5f7643bf9051"
      },
      "cell_type": "markdown",
      "source": "Some garages were built before whole property was built. I know that this situation may happen, but I assume that it doesn't. Also we have one observation with year of garage built higher than 2200."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8c7f208d8727ad1dbfad073399ebe8e5385793f2"
      },
      "cell_type": "code",
      "source": "train_test['GarageYrBlt'][train_test.YearBuilt>train_test.GarageYrBlt] =\\\ntrain_test['YearBuilt'][train_test.YearBuilt>train_test.GarageYrBlt]\ntrain_test.GarageYrBlt.loc[2592] = 2007",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "10c1fd13778370e5a11330a265c83ff69dca3db7"
      },
      "cell_type": "code",
      "source": "#train_test = train_test.replace({'GarageFinish':{'Fin':3,'RFn':2,'Unf':1,'Doesnt_exist':0}})\ntrain_test['GarageFinish'].loc[[2576,2126]] = 1\ntrain_test['GarageCars'].loc[[2576,2126]] = 1\ntrain_test['GarageArea'].loc[[2576]] = 288\ntrain_test['GarageQual'].loc[[2576,2126]] = 'TA'\ntrain_test['GarageCond'].loc[[2576,2126]] = 'TA'\ntrain_test[garage] = train_test[garage].fillna('No_garage')\ntrain_test = train_test.replace({'GarageType':{'2Types':6,'Attchd':5,'Basment':4,'BuiltIn':3,'CarPort':2,'Detchd':1,'No_garage':0},\n                                 'GarageQual':{'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1,'No_garage':0},\n                                 'GarageCond':{'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1,'No_garage':0},\n                                 'GarageFinish':{'Fin':3,'RFn':2,'Unf':1,'No_garage':0}})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2f60bc26e1d69bf80d5bec633c9cbb8fb8e5c97e"
      },
      "cell_type": "markdown",
      "source": "As GarageCars we've taken the most frequent value for houses older than 1930. For GarageArea we've aken median of GarageArea for garages with GarageCars equal to 1. For GarageQual and GarageCond we're taking 'TA', because this is most often value for garages built before 1930. Also 2610 observations has value of GarageCond equal to GarageQual. Rest of the observation does not have garage, so we can imput 'No_garage'."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "59674b41814bd84113c90c46899d850b41778d2a"
      },
      "cell_type": "code",
      "source": "basement = ['BsmtCond', 'BsmtExposure','BsmtQual','BsmtFinType2','BsmtFinType1','BsmtFinSF2','BsmtFinSF1','TotalBsmtSF','BsmtUnfSF']\n#2040, 2524, 2185, 2040 <-- imput BsmtCond\ntrain_test = train_test.replace({'BsmtQual':{'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1},\n                                 'BsmtCond':{'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1},\n                                 'BsmtExposure':{'Gd':4,'Av':3, 'Mn':2,'No':1,},\n                                 'BsmtFinType1':{'GLQ':6,'ALQ':5,'BLQ':4,'Rec':3,'LwQ':2,'Unf':1},\n                                 'BsmtFinType2':{'GLQ':6,'ALQ':5,'BLQ':4, 'Rec':3,'LwQ':2, 'Unf':1}})\ntrain_test.BsmtCond.loc[[2040, 2524, 2185, 2040]] = 3\n#2348, 1487, 948 <-- imput BsmtExposure\ntrain_test.BsmtExposure.loc[[2348,1487,948]] = 3\n#2217, 2218\ntrain_test.BsmtQual.loc[[2217, 2218]] = 3\ntrain_test['BsmtFinSF1'].loc[2284] = 638\ntrain_test['BsmtFinSF2'].loc[2284] = 0\ntrain_test['BsmtFinType2'].loc[332] = 1\ntrain_test[['BsmtFinType2', 'BsmtCond', 'BsmtQual', 'BsmtExposure', 'BsmtFinType1']]=\\\ntrain_test[['BsmtFinType2', 'BsmtCond', 'BsmtQual', 'BsmtExposure', 'BsmtFinType1']].fillna(0)\ntrain_test[['BsmtFinType2','BsmtFinType2']]=train_test[['BsmtFinType2','BsmtFinType2']].fillna(0)\ntrain_test[['BsmtFinSF1','BsmtFinSF2','TotalBsmtSF','BsmtUnfSF','BsmtHalfBath','BsmtFullBath']]=\\\ntrain_test[['BsmtFinSF1','BsmtFinSF2','TotalBsmtSF','BsmtUnfSF','BsmtHalfBath','BsmtFullBath']].fillna(0)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d5c64bab79664ae441014eb881303ea5d779ccf8"
      },
      "cell_type": "markdown",
      "source": "Beacause of weak correlations of BsmtCond, BsmtExposure we take mode value as impot for observations with NANs. For houses where we miss BsmtQual, but we know that basement appears we imput 3 as Quality (based on high correlation between YearBuilt and BsmtQual. Also houses below 1930 have median quality of 3). Also, there is one basement in which in my opinion it was wrongly declared that it has more than one finish type. One house with basement, but with missing BsmtFinType2 value received 1, because this is the most often appering value for houses where sum of basement finished is greater or equal basement unfinished area. Rest of the houses receive 0 value, because they just don't have basement."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d270e1040ea6d34448549be1ca55d476ff113d9b"
      },
      "cell_type": "code",
      "source": "train_test.MSZoning.loc[[1915,2216,2250]] = 'RM'\ntrain_test.MSZoning.loc[2904] = 'RL'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b8122d3fd019c3d88747f51e571b79a9d9c6fbb2"
      },
      "cell_type": "markdown",
      "source": "Here I'm imputing these values, because majority of observations from IDOTRR neighborhood live in RM. Same logic with Mitchel, but there is 90/10 proportion to RL"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2c2a0cc046af056f35deb997b30ec23485f24f7a"
      },
      "cell_type": "code",
      "source": "train_test = train_test.replace({'KitchenQual':{'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1}})\n\ntrain_test.Utilities = train_test.Utilities.fillna('AllPub')\ntrain_test.Functional = train_test.Functional.fillna('Typ')\ntrain_test.SaleType = train_test.SaleType.fillna('WD')\ntrain_test.KitchenQual.loc[1555] = 3\ntrain_test['Electrical'] = train_test['Electrical'].fillna('SBrkr')\ntrain_test[['Exterior1st','Exterior2nd']] = train_test[['Exterior1st','Exterior2nd']].fillna('VinylSd')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "855d87ed42b489ef24603e7f8e02c8ef56885b1c"
      },
      "cell_type": "markdown",
      "source": "Almost every obserbation have all utilities so I'm going to assume that NAs also have them. For KitchenQual we imput 3, because this is most frequently appearing number in this neighborhood"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c06029b5565f489a446e4ad84fb6a3ec9d907870"
      },
      "cell_type": "code",
      "source": "a = train_test[['OverallQual','MasVnrArea']][train_test.MasVnrArea>0]\na[['OverallQual','MasVnrArea']].groupby('OverallQual').median()\n\ntrain_test[['OverallQual','MasVnrArea']].groupby('OverallQual').median()\ntrain_test['MasVnrArea'][(train_test.MasVnrArea.isnull()) & (train_test.OverallQual==6)] = 203.0\ntrain_test['MasVnrArea'][(train_test.MasVnrArea.isnull()) & (train_test.OverallQual==7)] = 174\ntrain_test['MasVnrArea'][(train_test.MasVnrArea.isnull()) & (train_test.OverallQual==8)] = 257\ntrain_test['MasVnrArea'][(train_test.MasVnrArea.isnull()) & (train_test.OverallQual==10)] = 692",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "152ea329e4e71414e5898006abc85af4178996e4"
      },
      "cell_type": "markdown",
      "source": "In masony veneer area we're imputing median of area in each OverallQual category."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "af580e6b7a29b5390e00905dd829a72eadf24476"
      },
      "cell_type": "code",
      "source": "# train_test.dropna().corr(method='spearman').LotFrontage.sort_values(ascending=False).plot.bar()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8626a81af31191fc9f34bb12f34abee2f12909cb"
      },
      "cell_type": "code",
      "source": "# train_test.LotFrontage = train_test.LotFrontage.fillna(train_test.LotFrontage.median())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "126fc1c252cf37138519000b9addc1de52f05a55"
      },
      "cell_type": "code",
      "source": "a=train_test[(train_test.LotShape=='Reg') | (train_test.LotShape=='IR1')]\na=a[['LotFrontage','LotArea','LotShape']]\nb=a.LotFrontage**2\na=a.rename(columns={'LotFrontage':'LotFrontage^1'})\na=pd.concat([a,b],axis=1)\na=a.rename(columns={'LotFrontage':'LotFrontage^2'})\nc=a['LotFrontage^2']/a.LotArea\na=pd.concat([a,c],axis=1)\na=a.rename(columns={0:'Percentage_share_^2'})\na=a.dropna()\n\ntrain_test['LotFrontage'][(train_test.LotFrontage.isnull()) & (train_test.LotShape=='Reg')]=\\\n(train_test.LotArea[train_test.LotFrontage.isnull()]**(1/2))*(np.median(a['Percentage_share_^2'][a.LotShape=='Reg'])**(1/2))\n\ntrain_test['LotFrontage'][(train_test.LotFrontage.isnull()) & (train_test.LotShape=='IR1')]=\\\n(train_test.LotArea[train_test.LotFrontage.isnull()]**(1/2))*(np.median(a['Percentage_share_^2'][a.LotShape=='IR1'])**(1/2))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3a6d7092c92a5435bde4f15f7de5cd38fef389e6"
      },
      "cell_type": "code",
      "source": "# # plt, axarr = plt.subplots(figsize=(14,7))\n# # train_test.dropna().corr()['LotFrontage'].sort_values(ascending = False).plot.bar()\n# a = train_test[['LotFrontage','LotArea']][(train_test.LotFrontage <300) & (train_test.LotArea <100000)]\n\n# a.dropna().plot.scatter(x='LotArea', y='LotFrontage')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1de0f61b574ead113c7fdd1c806388cd53a12ccc"
      },
      "cell_type": "code",
      "source": "train_test = train_test.replace({'Street':{'Pave':1,'Grvl':0},\n                             'Alley':{'Doesnt_exist':0,'Grvl':1,'Pave':2},\n                             'Fence':{'GdPrv':4,'MnPrv':3,'GdWo':2,'MnWw':1,'Doesnt_exist':0},\n                             'Utilities':{'AllPub':4,'NoSewr':3,'NoSeWa':2,'ELO':1},\n                             'ExterQual':{'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1},\n                             'ExterCond':{'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1},\n                             'HeatingQC':{'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1},\n                             'CentralAir':{'Y':1,'N':0},\n                             'Functional':{'Typ':8,'Min2':7, 'Min1':6,'Mod':5,'Maj1':4,'Maj2':3,'Sev':2,'Sal':1},\n                             'PavedDrive':{'Y':3,'N':2,'P':1},\n                             'FireplaceQu':{'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1}})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "130e13ecd46944bc775918e58e3368f9d5bdbdff"
      },
      "cell_type": "markdown",
      "source": "Here we just changing ordinal scale so it is represented by numbers"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "26bf94535f68ac4ee1b77d45660b4ab32368003b"
      },
      "cell_type": "code",
      "source": "train_test['LotFrontage'][(train_test.LotFrontage.isnull()) & (train_test.LotShape=='IR2') ] = \\\nnp.median(train_test.LotFrontage[train_test.LotShape=='IR2'].dropna())\ntrain_test['LotFrontage'][(train_test.LotFrontage.isnull()) & (train_test.LotShape=='IR3') ] = \\\nnp.median(train_test.LotFrontage[train_test.LotShape=='IR3'].dropna())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e04ef5acacfe8070ab47f6f90717012c912c044b"
      },
      "cell_type": "markdown",
      "source": "Here we just adding median from IR2 and IR3 as LotFrontage for frontages with missing values"
    },
    {
      "metadata": {
        "_uuid": "79c4d5038ce4fc0050fb8dc4032da1212b1d2596"
      },
      "cell_type": "markdown",
      "source": "Before we will conver months into nominal variables, we're going to check whether we may assume that time series is stationary."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "11aaabdc17f1bd227ae59e7deab724f9373315e6"
      },
      "cell_type": "code",
      "source": "train_test.MoSold[train_test.YrSold==2010].value_counts()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "481ba2f29dee96d7d870b7962fcaaef1528dcb0e"
      },
      "cell_type": "code",
      "source": "train_set_copy=train_set[['SalePrice','YrSold','MoSold']]\ntrain_set_copy1=train_set_copy[train_set_copy.YrSold==2006]\ntrain_set_copy2=train_set_copy[train_set_copy.YrSold==2007].\\\nreplace({'MoSold':{1:13,2:14,3:15,4:16,5:17,6:18,7:19,8:20,9:21,10:22,11:23,12:24}})\ntrain_set_copy3=train_set_copy[train_set_copy.YrSold==2008].\\\nreplace({'MoSold':{1:25,2:26,3:27,4:28,5:29,6:30,7:31,8:32,9:33,10:34,11:35,12:36}})\ntrain_set_copy4=train_set_copy[train_set_copy.YrSold==2009].\\\nreplace({'MoSold':{1:37,2:38,3:39,4:40,5:41,6:42,7:43,8:44,9:45,10:46,11:47,12:48}})\ntrain_set_copy5=train_set_copy[train_set_copy.YrSold==2010].\\\nreplace({'MoSold':{1:49,2:50,3:51,4:52,5:53,6:54,7:55,8:56,9:57,10:58,11:59,12:60}})\n\ntrain_set_copy1=train_set_copy1[['SalePrice','MoSold']].groupby('MoSold').mean()\ntrain_set_copy2=train_set_copy2[['SalePrice','MoSold']].groupby('MoSold').mean()\ntrain_set_copy3=train_set_copy3[['SalePrice','MoSold']].groupby('MoSold').mean()\ntrain_set_copy4=train_set_copy4[['SalePrice','MoSold']].groupby('MoSold').mean()\ntrain_set_copy5=train_set_copy5[['SalePrice','MoSold']].groupby('MoSold').mean()\n\nTime_series=train_set_copy1.append([train_set_copy2,train_set_copy3,train_set_copy4,train_set_copy5]).reset_index()\nTime_series=Time_series.rename(columns={'MoSold':'t'})\nTime_series=Time_series.drop(54,axis=0)\n\nimport matplotlib.pyplot\n\nfig,axarr=matplotlib.pyplot.subplots(1,1,figsize=(12,5))\ntime_series=sns.lineplot(x='t',y='SalePrice',data=Time_series).set(xlabel='Time',ylabel='Sale Price')\nmatplotlib.pyplot.xticks(range(0,55))\ntime_series=sns.set_style('whitegrid')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aa63dda186b13e389944b99f44a481648f4eebbe"
      },
      "cell_type": "markdown",
      "source": "It seems that variance is varying in time. In order to approve intuition we're going to perform two tests: KPSS and ADF"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "8c7d7d9d83f9d5aa3d2f033fb3c35c652ebec017"
      },
      "cell_type": "code",
      "source": "train_set = train_test.loc[:1459]\ntrain_set = train_set.drop('Id',axis=1)\ncorrelation = train_set.corr(method='spearman').SalePrice.sort_values()\ncorrelation = pd.DataFrame(correlation)\nfig, axarr = matplotlib.pyplot.subplots(1,1,figsize=(70,180))\nbarplot = sns.barplot(data=correlation, y=correlation.index, x='SalePrice', orient='h')\nbarplot.tick_params(labelsize=60)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aa11dace6fbd447279efc6be42d6256789762ec9"
      },
      "cell_type": "code",
      "source": "kpss(train_set.SalePrice)\n\n#Augmented Dickey-Fuller unit root test\n\nadfuller(train_set.SalePrice)\n\n#Kwiatkowski–Phillips–Schmidt–Shin",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "44931e64030c9bb80b22f6f551aafea33dd265b9"
      },
      "cell_type": "markdown",
      "source": "Both tests indicates that it is nothing to worry in terms of non-stationarity"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d41008f22f9c8b105f1c51c5c1f5a93a0ca5d02a"
      },
      "cell_type": "code",
      "source": "train_test = train_test.replace({'MoSold':{1:'Jan',2:'Feb',3:'Mar',4:'Apr',5:'May',6:\\\n                                           'Jun',7:'Jul',8:'Aug',9:'Sep',10:'Oct',11:'Nov',12:'Dec'}})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5e637ddaa8d13f53865e005df74aadf271681446"
      },
      "cell_type": "markdown",
      "source": "Now, we're going to look for outliers in the most correlated variables"
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true,
        "_uuid": "3f5c32baf15a94a86c2e31e554e0ad1c71d4c088"
      },
      "cell_type": "code",
      "source": "fig, axarr=matplotlib.pyplot.subplots(6,3,figsize=(20,30))\nsns.scatterplot(x='OverallQual',y='SalePrice',data=train_set,ax=axarr[0][0])\nsns.scatterplot(x='GrLivArea',y='SalePrice',data=train_set,ax=axarr[0][1])\nsns.scatterplot(x='GarageCars',y='SalePrice',data=train_set,ax=axarr[0][2])\nsns.scatterplot(x='ExterQual',y='SalePrice',data=train_set,ax=axarr[1][0])\nsns.scatterplot(x='BsmtQual',y='SalePrice',data=train_set,ax=axarr[1][1])\nsns.scatterplot(x='KitchenQual',y='SalePrice',data=train_set,ax=axarr[1][2])\nsns.scatterplot(x='YearBuilt',y='SalePrice',data=train_set,ax=axarr[2][0])\nsns.scatterplot(x='GarageArea',y='SalePrice',data=train_set,ax=axarr[2][1])\nsns.scatterplot(x='FullBath',y='SalePrice',data=train_set,ax=axarr[2][2])\nsns.scatterplot(x='GarageFinish',y='SalePrice',data=train_set,ax=axarr[3][0])\nsns.scatterplot(x='TotalBsmtSF',y='SalePrice',data=train_set,ax=axarr[3][1])\nsns.scatterplot(x='1stFlrSF',y='SalePrice',data=train_set,ax=axarr[3][2])\nsns.scatterplot(x='YearRemodAdd',y='SalePrice',data=train_set,ax=axarr[4][0])\nsns.scatterplot(x='FireplaceQu',y='SalePrice',data=train_set,ax=axarr[4][1])\nsns.scatterplot(x='TotRmsAbvGrd',y='SalePrice',data=train_set,ax=axarr[4][2])\nsns.scatterplot(x='Fireplaces',y='SalePrice',data=train_set,ax=axarr[5][0])\nsns.scatterplot(x='GarageType',y='SalePrice',data=train_set,ax=axarr[5][1])\nsns.scatterplot(x='HeatingQC',y='SalePrice',data=train_set,ax=axarr[5][2])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true,
        "_uuid": "5b92e0131229d669f38b97c1ca899e8fa071590f"
      },
      "cell_type": "code",
      "source": "train_set[(train_set.OverallQual==10) & (train_set.SalePrice<200000)]\ntrain_test = train_test.drop([523,1298],axis=0)\n# train_set = train_set.drop([523,1298],axis=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "07b7b116709451122e1f3abfcce4d5e9a19f1d89"
      },
      "cell_type": "markdown",
      "source": "I assume that someone forgot about one zero at the end of sale price, but nevertheless, we're not going to implement this assumption - just delete it."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "75de99da7b5cf462666457230765fd09dbaf2dc1"
      },
      "cell_type": "code",
      "source": "train_set[(train_set.YearBuilt<1900) & (train_set.SalePrice>400000)]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cd68a3a330b344e5e3331231c142c245bec916b8"
      },
      "cell_type": "markdown",
      "source": "If it comes to this observation, mainly overall quality, and above grade living area justifies high price. Im going to let it be for now."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "12c4781bf2370538a712e1f23b52344f3eb501c5"
      },
      "cell_type": "code",
      "source": "train_set[(train_set.GarageArea>1200) & (train_set.SalePrice<300000)]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "93eb74da7b73be7adcae5187b79df52fbb65d951"
      },
      "cell_type": "markdown",
      "source": "Observation 1061 has garage bigger than entire above grade living area, 1190 almost same. Also 581 seems to be to small for this garage, and there isn't anything else that justifies high price"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "478c9b889cc37941c04053b254f9c3f714f56a4d"
      },
      "cell_type": "code",
      "source": "train_test = train_test.drop([581,1061,1190],axis=0)\n# train_set = train_set.drop([581,1061,1190],axis=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "175025dbc678c1a974530ee94c27731a498bba24"
      },
      "cell_type": "code",
      "source": "train_set[(train_set['YearRemodAdd']<1970) & (train_set.SalePrice>300000)]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a78b78a27babb12fe33ddfd5b262d0ebbd30df9a"
      },
      "cell_type": "code",
      "source": "train_test = train_test.drop(313,axis=0)\n# train_set = train_set.drop(313,axis=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e5d88718711f66920a41e849121dd4fe4f07fd94"
      },
      "cell_type": "markdown",
      "source": "Observation appears in upper limits of most the most correlated variables, so I don't think that there is anything that justifies such high price."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "092f8e513650360415bdc8ef5880607dbd45328a"
      },
      "cell_type": "code",
      "source": "train_set[(train_set['TotRmsAbvGrd']==14)]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ff278a53a788bdba95dec510929d62c6e0e9a7f7"
      },
      "cell_type": "markdown",
      "source": "This observation also has big above grade living area. On the other huge drawback may be lack of garage. Anyway, in my opinion its better to delete this observation."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "698b88ae8410d4b43a3f657a58a7d2f1e0c4a4a2"
      },
      "cell_type": "code",
      "source": "train_test = train_test.drop(635,axis=0)\n# train_set = train_set.drop(635,axis=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0e86838fccdc248a22825b3c1cbb76844d747f80"
      },
      "cell_type": "code",
      "source": "# fig, axarr=matplotlib.pyplot.subplots(5,1,figsize=(30,50))\n# sns.boxplot(x='OverallQual',y='SalePrice',data=train_set,ax=axarr[0])\n# sns.boxplot(x='GarageCars',y='SalePrice',data=train_set,ax=axarr[1])\n# sns.boxplot(x='ExterQual',y='SalePrice',data=train_set,ax=axarr[2])\n# sns.boxplot(x='BsmtQual',y='SalePrice',data=train_set,ax=axarr[3])\n# sns.boxplot(x='KitchenQual',y='SalePrice',data=train_set,ax=axarr[4])\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5c2b58b61979f7e4ddd0e52ae4ff4ff38e6e7794"
      },
      "cell_type": "code",
      "source": "# Nominal_data = ['MSSubClass','MSZoning','LotShape','LandContour','LotConfig','LandSlope','Neighborhood',\\\n#                 'Condition1','Condition2', 'BldgType','HouseStyle','YearRemodAdd',\\\n#                 'RoofStyle','RoofMatl', 'Exterior1st','Exterior2nd', 'MasVnrType','Foundation', 'Heating',\\\n#                 'Electrical','MiscFeature','SaleType', 'SaleCondition']\n\n# fig, axarr = matplotlib.pyplot.subplots(23,1,figsize=(30,300))\n# obj = train_set[Nominal_data]\n# obj = pd.concat([obj,train_set.SalePrice],axis=1)\n# for i, objects in enumerate(obj.drop('SalePrice',axis=1).columns,start=0):\n#     order = obj[['SalePrice',objects]].groupby(objects).median().sort_values(by='SalePrice').index\n#     sns.boxplot(y='SalePrice',x=objects,data=obj,ax=axarr[i],order=order)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b659eef254d4c01309b284627a53477d04c10ada"
      },
      "cell_type": "markdown",
      "source": "Based on the above charts i mainly had some thoughts about observations with SalePrice above 700000, but major quantitative variables justify high price. Also, I was wondering about observation from Old Town neighborhood with price over 400000, but other most important quantitative variables justify high price. Overall I was very understanding with outliers.\n\nObviouslly if model will not be satisfying we may experiment with deleting other outliers."
    },
    {
      "metadata": {
        "_uuid": "f6f103072fe39da69576d802b8126e008f95363b"
      },
      "cell_type": "markdown",
      "source": "Now in order to simplify dataset we're going to merge categories with similar distributions. In order to do this we will perform Kolmogorov-Smirnoff two sample test. We will set minimal sample size of the feature to 50 in order to minimize risk of not rejecting null hypotesis based on small sample size.\n\nIf certain feature will stay with only one unique value, then it gets deleted.\n\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6c781e84d2e4379c81473ad8c8c9d2dae009ce0f"
      },
      "cell_type": "code",
      "source": "categories = ['MSSubClass','MSZoning','LotShape','LandContour','LotConfig','LandSlope','Condition1','Condition2',\\\n               'BldgType','HouseStyle','RoofStyle','RoofMatl', 'Exterior1st','Exterior2nd',\\\n               'MasVnrType','Foundation', 'Heating', 'Electrical','MiscFeature','SaleType', 'SaleCondition',\\\n                'CentralAir','PoolQC']\n\ntrain_set = train_test[:1460]\n\ni=1\nwhile i!=0:\n    i=0\n    for category in categories:\n        for combination in list(combinations(train_set[category].value_counts().index,2)):\n            if len(train_set.SalePrice[train_set[category]==combination[0]])<20 or len(train_set.SalePrice[train_set[category]==combination[1]])<20:\n                continue\n            else:\n                ks_result=mannwhitneyu(train_set.SalePrice[train_set[category]==combination[0]],\n                                train_set.SalePrice[train_set[category]==combination[1]])[1]\n                \n                if ks_result>0.05:\n                    train_set[category]=train_set[category].replace(combination[0],'{}+{}'.format(combination[0],combination[1]))\n                    train_set[category]=train_set[category].replace(combination[1],'{}+{}'.format(combination[0],combination[1]))\n                    i=i+1\n                        \n                    train_test[category]=train_test[category].replace(combination[0],'{}+{}'.format(combination[0],combination[1]))\n                    train_test[category]=train_test[category].replace(combination[1],'{}+{}'.format(combination[0],combination[1]))\n        \nfor feature in categories:\n    if len(train_test[feature].value_counts())==1:\n        train_test=train_test.drop(feature,axis=1)\n        train_set=train_set.drop(feature,axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b918a395d8fe533cc2b366fbebb2d7bc4b96caf8"
      },
      "cell_type": "code",
      "source": "# train_test = train_test.replace({'BsmtFinType1':{'5.0+2.0':2,'4.0+3.0':2,6.0:3},\n#                                  'OverallCond':{'6+7+8':6,9:7},\n#                                  'BsmtFinType2':{'1.0+2.0':1,'3.0+4.0':2,5.0:3,6.0:4},\n#                                  'Functional':{'7+6':6,8:7},\n#                                  'PavedDrive':{'2+1':0,3:1},\n#                                  'BsmtExposure':{'3.0+2.0':2,4:3},\n#                                  'BsmtQual':{'0.0+2.0':0,3:1,4:2},\n#                                  'BsmtCond':{'2.0+0.0':0,3.0:1,4:2},\n#                                  'GarageCond':{'0+2':0,3:1,4:2},\n#                                  'Fence':{'0+4':0,'3+2':1}})\n\n# train_test = train_test.replace({'BsmtQual':{5:3},\n#                                 'BsmtCond':{1:0},\n#                                 'GarageCond':{5:3}})\n\n# train_set = train_set.replace({'BsmtFinType1':{'5.0+2.0':2,'4.0+3.0':2,6.0:3},\n#                                  'OverallCond':{'6+7+8':6,9:7},\n#                                  'BsmtFinType2':{'1.0+2.0':1,'3.0+4.0':2,5.0:3,6.0:4},\n#                                  'Functional':{'7+6':6,8:7},\n#                                  'PavedDrive':{'2+1':0,3:1},\n#                                  'BsmtExposure':{'3.0+2.0':2,4:3},\n#                                  'BsmtQual':{'0.0+2.0':0,3:1,4:2},\n#                                  'BsmtCond':{'2.0+0.0':0,3.0:1,4:2},\n#                                  'GarageCond':{'0+2':0,3:1,4:2},\n#                                  'Fence':{'0+4':0,'3+2':1}})\n\n# train_set = train_set.replace({'BsmtQual':{5:3},\n#                                 'BsmtCond':{1:0},\n#                                 'GarageCond':{5:3}})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a313cbb671d669982175bd331152a806801ce75e"
      },
      "cell_type": "code",
      "source": "# correlation_update = train_set[['BsmtFinType1','OverallCond','BsmtFinType2','Functional','PavedDrive',\\\n#                                 'BsmtExposure','BsmtQual','BsmtCond','GarageCond','Fence','SalePrice']].corr()['SalePrice']\n\n# correlation = correlation.loc[['BsmtFinType1','OverallCond','BsmtFinType2','Functional','PavedDrive',\\\n#                                 'BsmtExposure','BsmtQual','BsmtCond','GarageCond','Fence','SalePrice']]\n# (np.absolute(correlation_update) > np.absolute(correlation))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d2fa3aefa21d40c8c6960377156bd7203a696abc"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b824071b6b128a3640b89383b5b131aa174e266d"
      },
      "cell_type": "markdown",
      "source": "After transformation by using KS two sample test every absolute value of correlation between feature and SalePrice has increased. Because of that i think, that this change was reasonable.\n\nNow, we're going to make some feature engineering along with removing skewnessess and stuff."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "922c0ff6503f62bffffe87e84700e9fa7a1a35f2"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "93805f96e9d44784783c1512db1df02f772b63d9",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "basement = ['BsmtCond', 'BsmtExposure','BsmtQual','BsmtFinType2','BsmtFinType1','BsmtFinSF2','BsmtFinSF1','TotalBsmtSF','BsmtUnfSF']\nfig, axarr = plt.subplots(9,1,figsize=(20,70))\nsns.distplot(train_test[basement[0]],kde=False,bins=6,ax = axarr[0])\nsns.distplot(train_test[basement[1]],kde=False,bins=6,ax = axarr[1])\nsns.distplot(train_test[basement[2]],kde=False,bins=4,ax = axarr[2])\nsns.distplot(train_test[basement[3]],kde=False,bins=4,ax = axarr[3])\nsns.distplot(train_test[basement[4]],kde=False,bins=4,ax = axarr[4])\nsns.distplot(train_test[basement[5]],kde=False,bins=4,ax = axarr[5])\nsns.distplot(train_test[basement[6]],kde=False,bins=4,ax = axarr[6])\nsns.distplot(train_test[basement[7]],kde=False,bins=10,ax = axarr[7],)\nsns.distplot(train_test[basement[8]],kde=False,bins=6,ax = axarr[8])\n\n#Basement binning\n\ntrain_test['TotalBsmtSF'].loc[2549] = 3200\ntrain_test['BsmtCondBin*'] = train_test.BsmtCond.map(lambda x: 2 if x>2 else 1)\ntrain_test['BsmtExposureBin*'] = train_test.BsmtExposure.map(lambda x: 2 if x>1 else 1)\ntrain_test['BsmtQualBin*'] = 1\ntrain_test['BsmtQualBin*'] = train_test.BsmtQual.map(lambda x: 3 if x>2 else 1)\ntrain_test['TotalBsmtSFBin*'] = pd.cut(train_test.TotalBsmtSF,10, labels=range(1,11)).astype(int)\ntrain_test['BsmtUnfSFBin*'] = pd.cut(train_test.BsmtUnfSF,10, labels=range(1,11)).astype(int)\ntrain_test['TotalBsmtSFBinRoot*'] = train_test['TotalBsmtSFBin*']**(1/2)\ntrain_test['BsmtUnfSFBinRoot*'] = train_test['BsmtUnfSFBin*']**(1/2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "7974469135ddc686efcffb1fb31e6bd659a4e2ed"
      },
      "cell_type": "code",
      "source": "fig, axarr = plt.subplots(7,1,figsize=(20,50))\ngarage = ['GarageType','GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond']\nsns.distplot(train_test[garage[0]],kde=False,bins=3,ax = axarr[0])\nsns.distplot(train_test[garage[1]].replace('No_garage',1800),kde=False,bins=2,ax = axarr[1])\nsns.distplot(train_test[garage[2]],kde=False,bins=4,ax = axarr[2])\nsns.distplot(train_test[garage[3]],kde=False,bins=2,ax = axarr[3])\nsns.distplot(train_test[garage[4]],kde=False,bins=6,ax = axarr[4])\nsns.distplot(train_test[garage[5]],kde=False,bins=4,ax = axarr[5])\nsns.distplot(train_test[garage[6]],kde=False,bins=4,ax = axarr[6])\n\n\ntrain_test['GarageTypeBin*'] = pd.cut(train_test.GarageType,3,labels=[1,2,3]).astype(int)\ntrain_test['GarageYrBltBin*'] = pd.cut(train_test[garage[1]].replace('No_garage',1800),2,labels=[1,2]).astype(int)\ntrain_test['GarageFinishBin*'] = pd.cut(train_test.GarageFinish,4,labels=[1,2,3,4]).astype(int)\ntrain_test['GarageCarsBin*'] = pd.cut(train_test.GarageCars,2,labels=[1,2]).astype(int)\ntrain_test['GarageAreaBin*'] = pd.cut(train_test.GarageArea,6,labels=[1,2,3,4,5,6]).astype(int)\ntrain_test['GarageQualBin*'] = train_test.GarageQual.map(lambda x: 2 if x>2 else 1)\ntrain_test['GarageCondBin*'] = train_test.GarageCond.map(lambda x: 2 if x>2 else 1)\n\ntrain_test['GarageAreaBinRoot*'] = train_test['GarageAreaBin*']**(1/2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f6131c630092b3f04558bf84d5a07c1e375557dc"
      },
      "cell_type": "code",
      "source": "# train_test = train_test.drop(['BsmtFullBath','BsmtHalfBath'],axis=1)\n# train_test = pd.concat([train_test,BsmtBath],axis=1).rename(columns={0:'BsmtBath'})\n\ntrain_test['GarageQuality*'] = train_test.GarageQual + train_test.GarageCond\ntrain_test['HasPool*'] = 0\ntrain_test['HasPool*'][train_test.PoolQC>0] = 1\n\ntrain_test['HasGarage*'] = train_test.GarageFinish.map(lambda x: 1 if x>0 else 0)\ntrain_test['HasFireplace*'] = train_test.Fireplaces.map(lambda x: 1 if x>0 else 0)\ntrain_test['Fireplaces*FireplaceQu*'] = train_test.Fireplaces * train_test.FireplaceQu\n\ntrain_test['HasBasement*'] = train_test.TotalBsmtSF.map(lambda x: 1 if x>0 else 0)\n\n\nclosed = train_test['EnclosedPorch'] + train_test['3SsnPorch'] + train_test['ScreenPorch'] \nopened = train_test['WoodDeckSF'] + train_test['OpenPorchSF']\ntrain_test['PorchArea*'] = closed + opened\ntrain_test['HasPorch*'] = 0\ntrain_test['HasPorch*'] = train_test['PorchArea*'].map(lambda x: 1 if x>0 else 0)\ntrain_test['PorchClosed*'] = closed.map(lambda x: 1 if x > 0 else 0)\n\ntrain_test['BsmtFinType*'] = train_test.BsmtFinType2 + train_test.BsmtFinType1\ntrain_test['BsmtUnfinPercent*'] = train_test.BsmtUnfSF / train_test.TotalBsmtSF\ntrain_test['BsmtUnfinPercent*'][train_test['BsmtUnfinPercent*'].isnull()] = 0\ntrain_test['TotalHouseSF*'] = train_test.TotalBsmtSF + train_test.GrLivArea + train_test.TotalBsmtSF\n\nIsFresh = train_test[(train_test.YearRemodAdd == train_test.YrSold)].index\ntrain_test['IsFresh*'] = 0\ntrain_test['IsFresh*'].loc[IsFresh] = 1\n\ntrain_test['AmtOfStories*'] = 0\ntrain_test['AmtOfStories*'][train_test.HouseStyle=='1Story'] = 1\ntrain_test['AmtOfStories*'][(train_test.HouseStyle=='1.5Fin') | (train_test.HouseStyle=='1.5Unf')] = 1.5\ntrain_test['AmtOfStories*'][(train_test.HouseStyle=='2.5Fin') | (train_test.HouseStyle=='2.5Unf')] = 2.5\ntrain_test['AmtOfStories*'][(train_test.HouseStyle=='2Story')] = 2\n\ntrain_test['AllStoriesFinished*'] = 1\ntrain_test['AllStoriesFinished*'][(train_test['HouseStyle']=='1.5Unf') | (train_test['HouseStyle']=='2.5Unf')] = 0\n\n\ntrain_test['OverallQuality*'] = train_test.OverallQual * train_test.OverallCond\ntrain_test['BasementQuality*'] = train_test.BsmtCond * train_test.BsmtExposure\ntrain_test['BsmtFinishType*'] = train_test.BsmtFinType1 * train_test.BsmtFinType2\ntrain_test = train_test.drop(['BsmtFinType1', 'BsmtFinType2'], axis=1)\ntrain_test['Bathrooms*'] = train_test.BsmtFullBath + train_test.BsmtHalfBath/2 + train_test.FullBath + train_test.HalfBath/2\ntrain_test['ExteriorQuality*'] = train_test.ExterQual * train_test.ExterCond\n\n\ntrain_test.GarageYrBlt = train_test.GarageYrBlt.replace('No_garage',0)\ntrain_test['NewGarage*'] = 0\ntrain_test['NewGarage*'][train_test.GarageYrBlt>2000]=1\n# train_test = train_test.drop('GarageYrBlt',axis=1)\n# train_test.GarageYrBlt[train_test.GarageYrBlt==0] = train_test.YearBuilt\n\ntrain_test['HasGarage*'] = train_test.GarageArea.map(lambda x: 1 if x > 0 else 0)\n\ntrain_test['CanHold2Cars'] = train_test.GarageCars.map(lambda x: 1 if x>=2 else 0)\ntrain_test['BsmtFinSF*'] = train_test.BsmtFinSF1 + train_test.BsmtFinSF2\n\n\n# train_test = train_test.drop(['BsmtFullBath','BsmtHalfBath','FullBath','HalfBath'],axis=1)\n# train_test = train_test.drop(['YrSold','MoSold'],axis=1)\ntrain_test['YearBltandYearRemodAdd'] = train_test.YearBuilt + train_test.YearRemodAdd\ntrain_test = train_test.drop('Utilities',axis=1)\n\n\na = train_test[:1459][['Neighborhood','SalePrice']].groupby('Neighborhood').mean().sort_values(by='SalePrice')\ntrain_test['RichNeighborhood'] = 1\nones = a[0:3].index\ntwos = a[3:12].index\nthrees = a[12:19].index\nfours = a[19:22].index\nfives = a[22:].index\ni=0\nfor variable in [ones, twos, threes, fours, fives]:\n    i += 1\n    for neighborhood in variable:\n        train_test['RichNeighborhood'][train_test.Neighborhood==neighborhood] = i",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bce94974fcd548e4b43a8e4a41b624c073af5934"
      },
      "cell_type": "code",
      "source": "# # Interval data = [,'LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF',\\\n# #                  'TotalBsmtSF','1stFlrSF', '1stFlrSF', 'LowQualFinSF', 'GrLivArea', \\\n# #                  ,'GarageArea','WoodDeckSF','OpenPorchSF', 'EnclosedPorchSF', '3SsnPorch',\\\n# #                  'ScreenPorch', 'PoolArea','MiscVal', 'YearBlt', 'YearRemodAdd', 'YearBltandYearRemodAdd','TotalHouseSF*']\n\n# for i in train_test.select_dtypes(exclude=object).columns:\n#     train_test['{}SQUA'.format(i)] = train_test[i]**2\n#     train_test['{}CUBE'.format(i)] = train_test[i]**3\n    \n# train_test = train_test.drop('SalePriceSQUA',axis=1)\n# train_test = train_test.drop('SalePriceCUBE',axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b79f4a3802d788c250a84deaa388205785e86c5c"
      },
      "cell_type": "code",
      "source": "train_test['LnBsmtQual*'] = np.log(train_test.BsmtQual+1)\ntrain_test['LnExterQual*'] = np.log(train_test.ExterQual)\ntrain_test['LnKitchenQual*'] = np.log(train_test.KitchenQual)\ntrain_test['LnOverallQual*'] = np.log(train_test.OverallQual)\ntrain_test['LnBathrooms*'] = np.log(train_test['Bathrooms*'])\ntrain_test['LnGarageCars*'] = np.log(train_test['GarageCars']+1)\ntrain_test['LnGarageArea*'] = np.log(train_test['GarageArea']+1)\n# train_test['StandCbrtGarageArea'] = np.cbrt(((train_test.GarageArea+1)-np.mean(train_test.GarageArea))/np.std(train_test.GarageArea))\ntrain_test['LnTotRmsAbvGrd*'] = np.log(train_test['TotRmsAbvGrd'])\ntrain_test['LnOpenPorchSF*'] = np.log(train_test['OpenPorchSF']+1)\ntrain_test['LnLotArea*'] = np.log(train_test['LotArea'])\ntrain_test['LnPorchArea*'] = np.log(train_test['PorchArea*']+1)\ntrain_test['LnLotFrontage*'] = np.log(train_test['LotFrontage'])\ntrain_test['LnFireplaceQu*'] = np.log(train_test.FireplaceQu + 1)\ntrain_test['LnFireplaces*'] = np.log(train_test.Fireplaces + 1)\ntrain_test['LnGrLivArea*'] = pd.Series(np.log(train_test.GrLivArea))\ntrain_test['Ln1stFlrSF*'] = pd.Series(np.log(train_test['1stFlrSF']))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2ba88e84540d929243d2fef7faffc72c4f6b18fb"
      },
      "cell_type": "markdown",
      "source": "We connect two columns - BsmtFullBath and BsmtHalfBath in order to provide more informations in one column."
    },
    {
      "metadata": {
        "_uuid": "023387deddad743d624bc09d6c7cc12b89904dad"
      },
      "cell_type": "markdown",
      "source": "Creates new variable which indicates whether given observation has pool or not. Als wanted to underline here, that correlations between OverallQual and Cond, BsmtQual and Cond, GarageQual and Cond have week correlation, so there is no point in thinking that they descriebe same thing."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ee9dc01494a10cf356ea4062fee8ec236c6ccbee"
      },
      "cell_type": "code",
      "source": "# train_test[train_test['EnclosedPorch']>0] #459\n# len(train_test[train_test['3SsnPorch']>0]) #37\n# len(train_test[train_test['ScreenPorch']>0]) #256  sum(752)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ad1ce2d960f0aa770fc704668121441ced69d806"
      },
      "cell_type": "code",
      "source": "# order = train_test[:1459][['Neighborhood','SalePrice']].groupby('Neighborhood').median().sort_values(by='SalePrice').index\n\n# fig, axarr = plt.subplots(figsize=(17,10))\n# sns.barplot(x='Neighborhood',y='SalePrice',data=train_test[:1459], order=order)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true,
        "_uuid": "b4f178b085b8b2c064343eeafb02fc5c7bc796a8"
      },
      "cell_type": "code",
      "source": "# a = train_test[:1459][['Neighborhood','SalePrice']].groupby('Neighborhood').mean().sort_values(by='SalePrice')\n\n# fig, axarr = plt.subplots(figsize=(15,7))\n# sns.barplot(x=a.index,y='SalePrice',data=a)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "4f30589925c8c39134a6bc5cd137f6df5865cee8"
      },
      "cell_type": "code",
      "source": "# a = train_test[:1459][['Neighborhood','SalePrice']].groupby('Neighborhood').mean().sort_values(by='SalePrice')\n# train_test['RichNeighborhood'] = 1\n# ones = a[0:3].index\n# twos = a[3:9].index\n# threes = a[9:12].index\n# fours = a[12:15].index\n# fives = a[15:].index\n# i=0\n# for variable in [ones, twos, threes, fours, fives]:\n#     i += 1\n#     for neighborhood in variable:\n#         train_test['RichNeighborhood'][train_test.Neighborhood==neighborhood] = i",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7126ae17cd209cb640f1d47b0121c74c6df629e8"
      },
      "cell_type": "code",
      "source": "# Continous = ['GrLivArea','YearBuilt','GarageArea','TotalBsmtSF','1stFlrSF','PorchArea'\n# 'TotalHouseSF']\n# fig, axarr = plt.subplots(1,2,figsize=(17,7))\n\n# x = train_test['YearBuilt']\n\n# sns.distplot(x,ax=axarr[0])\n# scipy.stats.probplot(x, plot=plt)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true,
        "_uuid": "80ae351cb64d8822f9b00bfe7f097f8a69e7545f"
      },
      "cell_type": "code",
      "source": "fig, axarr = plt.subplots(1,1,figsize=(14,7),sharex=True)\n\na = train_set[['SaleType','SalePrice']].groupby('SaleType').median()\ntrain_test.SaleType.value_counts().plot.bar()\nprint(train_test.SaleType.value_counts())\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dfcbf2a9ea934947877eadb344c4ebc53834b5a9"
      },
      "cell_type": "code",
      "source": "train_test = train_test.replace({'BldgType':{'Duplex':'Other', 'Twnhs':'Other', '2fmCon':'Other'},\n                                'Electrical':{'FuseF':'Other','FuseP':'Other','Mix':'Other'},\n                                 'Foundation':{'Slab':'Other','Stone':'Other','Wood':'Other'},\n                                 'Heating':{'Grav':'Other','Wall':'Other','OthW':'Other','Floor':'Other'},\n                                 'HouseStyle':{'2.5Unf':'Other','1.5Unf':'Other','2.5Fin':'Other'},\n                                 'MSSubClass':{'1-1/2 STORY PUD - ALL AGES':'Other','1-STORY W/FINISHED ATTIC ALL AGES':'Other'\\\n                                 ,'PUD - MULTILEVEL - INCL SPLIT LEV/FOYER':'Other','1-1/2 STORY - UNFINISHED ALL AGES':'Other'\\\n                                 ,'2-1/2 STORY ALL AGES':'Other'},\n                                 'MSZoning':{'RH':'Other','C (all)':'Other'},\n                                 'MiscFeature':{'Gar2':'Other','TenC':'Other'},\n                                 'RoofMatl':{'Tar&Grv':'Other', 'WdShake':'Other', 'WdShng1':'Other', 'Metal':'Other', 'Roll':'Other', 'Membran':'Other'},\n                                 'RoofStyle':{'Gambrel':'Other', 'Flat':'Other', 'Mansard':'Other', 'Shed':'Other'},\n                                 'SaleCondition':{'Alloca':'Other','AdjLand':'Other'},\n                                 'SaleType':{'ConLD':'Other', 'CWD':'Other', 'ConLI':'Other', 'ConLw':'Other', 'Oth':'Other', 'Con':'Other'}})\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ddd3ec61705d7cc31ccaa172a243d1b53555df3b"
      },
      "cell_type": "code",
      "source": "train_test = pd.get_dummies(train_test)\n# train_set = pd.get_dummies(train_set)\ntrain_test = train_test.drop('Id',axis=1)\n# train_set = train_set.drop('Id',axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ade32482912428c04a41d67a8be539f3ffa4528d"
      },
      "cell_type": "code",
      "source": "# correlation = train_test[:1453].corr(method='spearman').SalePrice.sort_values()\n# correlation = pd.DataFrame(correlation)\n# fig, axarr = matplotlib.pyplot.subplots(1,1,figsize=(70,240))\n# barplot = sns.barplot(data=correlation, y=correlation.index, x='SalePrice', orient='h')\n# barplot.tick_params(labelsize=60)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4d635cad263a503320ae8c83903d33ca1d4f4061"
      },
      "cell_type": "code",
      "source": "# fig, axarr = plt.subplots(1,2,figsize=(17,7))\n# sns.distplot(np.log(train_test.LotFrontage),ax=axarr[0])\n# scipy.stats.probplot(np.log(train_test.LotFrontage), plot=plt)\n\n\n\n\n\n\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c6c3f50dafece95d16c86385b4411fbaf3d3e5ec"
      },
      "cell_type": "code",
      "source": "low_val = np.array([])\nfor clean in train_test.columns:\n    if len(train_test[(train_test[clean].isnull()) | (train_test[clean]==0)]) >= len(train_test)*(1-0.001):\n        low_val = np.append(low_val,clean)\n        train_test = train_test.drop(clean, axis=1)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "be779d9e6403565b0dfcaa6f8ba8a5973e6a3fb3"
      },
      "cell_type": "code",
      "source": "for i in list(combinations(train_test.columns,2)):\n    if i[0] in train_test.columns and i[1] in train_test.columns:\n        corr = spearmanr(train_test[i[0]],train_test[i[1]])\n        if np.abs(corr[0])>=0.9:\n            if spearmanr(train_test.SalePrice[:1450],train_test[i[0]][:1450])[0]>\\\n            spearmanr(train_test.SalePrice[:1450],train_test[i[1]][:1450])[0]:\n                train_test = train_test.drop(i[1],axis=1)\n            else:\n                train_test = train_test.drop(i[0],axis=1)\n        else:\n            continue\n    \n    else:\n        continue\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "907256060c0deb204f48c772f8bf313962636759"
      },
      "cell_type": "code",
      "source": "# from sklearn.linear_model import LinearRegression\n# import sys\n\n# def variance_inflation_factor_test(X_array, X_exog):\n#     X_exog1 = X_exog.copy()\n#     X_array = X_array.drop(X_exog1.name, axis=1)\n#     model = LinearRegression()\n#     model.fit(X_array, X_exog)\n#     return 1 / (1 - model.score(X_array, X_exog))\n\n# for column in train_test.drop('SalePrice',axis=1).columns:\n#     VIF_result = variance_inflation_factor_test(train_test.drop('SalePrice',axis=1), train_test[column])\n#     if VIF_result > 10:\n#         train_test = train_test.drop(column,axis=1)\n# #         train_set = train_set.drop(column,axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "83933728e6659b8bb54eba370a4c2a4b237507b0"
      },
      "cell_type": "code",
      "source": "\n# # Create the RFE object and rank each pixel\n# clf_rf_3 = RandomForestClassifier()      \n# rfe = RFE(estimator=clf_rf_3, n_features_to_select=10, step=1)\n# rfe = rfe.fit(train_X, train_y.astype(int))\n# print('Chosen best 5 feature by rfe:',train_X.columns[rfe.support_])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "26f2b7d977b1ea8a9c59006942022fb4439ae022"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "2c528f3bcdf061d0077746db60742ff240647dba"
      },
      "cell_type": "code",
      "source": "# find best scored 5 features\n\nselect_feature = SelectKBest(f_classif).fit(train_test.drop('SalePrice',axis=1)[:1450], np.log(train_test.SalePrice[:1450]).astype(int))\n\nscores = pd.DataFrame({'Features':train_test.drop('SalePrice',axis=1)[:1450].columns,'Scores':select_feature.scores_}).sort_values(by='Scores',ascending=False)\n\nscores = scores.set_index('Features')\nscores['Position'] = range(1,len(scores)+1)\nscores",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9a37fafb94409960e4496c47b7c50f59332faf06"
      },
      "cell_type": "code",
      "source": "# a = train_test.drop(np.array(scores[scores.Scores>50000].Features),axis=1)\n# a = a.drop('SalePrice',axis=1)\n# b = train_test.drop(a,axis=1)\n# b",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "e4a2a9e27753bae9a14299af8fd0c10642978fd0"
      },
      "cell_type": "code",
      "source": "# # The \"accuracy\" scoring is proportional to the number of correct classifications\n# AmountOfFeatures = np.array([])\n# Features = np.array([])\n# # for i in range(20):\n# print(i)\n# clf_rf_4 = RandomForestClassifier() \n# rfecv = RFECV(estimator=clf_rf_4, step=1, cv=5,scoring='accuracy')   #5-fold cross-validation\n# rfecv = rfecv.fit(train_test.drop(['SalePrice'],axis=1)[:1453], np.log(train_test.SalePrice)[:1453].astype(int))\n# AmountOfFeatures = np.append(AmountOfFeatures,rfecv.n_features_)\n# Features = np.append(Features, train_test.drop(['SalePrice'],axis=1)[:1453].columns[rfecv.support_])\n# #     print('Optimal number of features :', rfecv.n_features_)\n# #     print('Best features :', train_test.drop(['SalePrice'],axis=1)[:1453].columns[rfecv.support_])\n\n# print(pd.Series(Features).value_counts())\n# print(AmountOfFeatures)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "b17db2a24c9d87f125f222ee25787741c1cf54ac"
      },
      "cell_type": "code",
      "source": "# Features1= pd.Series(Features)\n# Features1 = Features1.value_counts()\n# Features1 = pd.DataFrame(Features1)\n# Features1 = Features1.sort_index(ascending=True)\n# Features1 = Features1.rename(columns={0:'Appearances'})\n# final = pd.concat([Features1,scores],axis=1)\n# final.sort_values(by='Scores',ascending=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5536aa7e54195227bceb19f7af2a1060be7d4623"
      },
      "cell_type": "code",
      "source": "# # final.sort_values(by='Appearances',ascending=False)\n# a = Features1[Features1.Appearances>=4]\n# len(a)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b2ef1e1da61851deb8828d3c23dcbdadda113c97"
      },
      "cell_type": "code",
      "source": "# a = train_test.drop(['SalePrice'],axis=1)[:1453].columns[rfecv.support_]\n# b = train_test.drop(a,axis=1)\n# b = b.drop('SalePrice',axis=1)\n# train_test = train_test.drop(b,axis=1)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a25b640e8f042d48f2dc20a2267306d79a305167"
      },
      "cell_type": "code",
      "source": "# c = train_test.drop(a.index,axis=1)\n# c = c.drop('SalePrice',axis=1)\n# d = train_test.drop(c,axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "822e922a482f38f857e2fb80f4bbec312ab0475b"
      },
      "cell_type": "code",
      "source": "# from sklearn.linear_model import Lasso\n# from xgboost import XGBRegressor\n\n\n# x=[]\n# y = []\n# # for i in range(20):\n# train_X, test_X, train_y, test_y = train_test_split(train_test.drop(['SalePrice'],axis=1)[:1453],\\\n#                                         np.log(train_test.SalePrice)[:1453],random_state=4)\n# for feat in scores.index[:-1]:\n#     train_X = train_X.drop(feat,axis=1)\n#     test_X = test_X.drop(feat,axis=1)\n#     model = Lasso(alpha=0.0001)\n#     model.fit(train_X, train_y)\n#     pred = np.exp(model.predict(test_X))\n#     actual = np.exp(test_y)\n\n#     actual = np.log(actual)\n#     predicted = np.log(pred)\n#     error1 = np.sqrt(np.sum(np.square(actual-predicted))/len(actual))\n#     x.append(error1)\n\n#     pred1 = np.exp(model.predict(train_X))\n#     actual1 = np.exp(train_y)\n\n#     actual1 = np.log(actual1)\n#     predicted1 = np.log(pred1)\n#     error2 = np.sqrt(np.sum(np.square(actual1-predicted1))/len(actual1))\n#     y.append(error2)\n\n# res = pd.DataFrame({'TrainSet':y,'TestSet':x})\n# fig, axarr = plt.subplots(figsize=(20,8))\n# sns.lineplot(data=res)\n# # print('TRAIN DATA\\n','Median:',np.median(y),'Max:',np.max(y),'Min:',np.min(y))\n# # print('TEST DATA\\n','Median:',np.median(x),'Max:',np.max(x),'Min:',np.min(x))\n# # print('Difference between sets:',np.median(x)-np.median(y))\n# # # a = pd.DataFrame({'alpha':[i],'error':[err]})\n# # # error = pd.concat([error, a],axis=0)\n\n# # # fig, axarr = plt.subplots(figsize=(15,7))\n# # # error.plot.scatter(x = 'alpha', y = 'error',ax=axarr)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5a95be7be187c147c434388480c147ad1f7c5ea9"
      },
      "cell_type": "code",
      "source": "# from sklearn.linear_model import Lasso\n# from xgboost import XGBRegressor\n\n\n# x=[]\n# y = []\n# # for i in range(20):\n# train_X, test_X, train_y, test_y = train_test_split(train_test.drop(['SalePrice'],axis=1)[:1453],\\\n#                                     np.log(train_test.SalePrice)[:1453],random_state=1)\n\n# model = XGBRegressor(learning_rate=0.01,\n#                     n_estimators=1000,\n#                     max_depth=3,\n#                     subsample=0.8,\n#                     colsample_bytree=0.3,\n#                     gamma=0)\n\n# model.fit(train_X, train_y)\n# pred = np.exp(model.predict(test_X))\n# actual = np.exp(test_y)\n\n# actual = np.log(actual)\n# predicted = np.log(pred)\n# error1 = np.sqrt(np.sum(np.square(actual-predicted))/len(actual))\n# x.append(error1)\n\n# pred1 = np.exp(model.predict(train_X))\n# actual1 = np.exp(train_y)\n\n# actual1 = np.log(actual1)\n# predicted1 = np.log(pred1)\n# error2 = np.sqrt(np.sum(np.square(actual1-predicted1))/len(actual1))\n# y.append(error2)\n\n# res = pd.DataFrame({'TrainSet':y,'TestSet':x})\n\n# # print('TRAIN DATA\\n','Median:',np.median(y),'Max:',np.max(y),'Min:',np.min(y))\n# # print('TEST DATA\\n','Median:',np.median(x),'Max:',np.max(x),'Min:',np.min(x))\n# # print('Difference between sets:',np.median(x)-np.median(y))\n# # # a = pd.DataFrame({'alpha':[i],'error':[err]})\n# # # error = pd.concat([error, a],axis=0)\n\n# # # fig, axarr = plt.subplots(figsize=(15,7))\n# # # error.plot.scatter(x = 'alpha', y = 'error',ax=axarr)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b65a72cf2a29408d7e9b4f302aa17b54cbf9dd29"
      },
      "cell_type": "code",
      "source": "# fig, axarr = plt.subplots(figsize=(15,10))\n# sns.lineplot(data=res)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "f81cf90a3c50b5f7c2a2be67c81babffb07a94f3"
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import Lasso\nfrom xgboost import XGBRegressor\n\n\nx=[]\ny = []\n# for i in range(20):\ntrain_X, test_X, train_y, test_y = train_test_split(train_test.drop(['SalePrice'],axis=1)[:1453],\\\n                                    np.log(train_test.SalePrice)[:1453],random_state=1)\n\nerror = pd.DataFrame({'alpha':[],'error':[]})\nmodel = Lasso(alpha = 0.00010)\nmodel.fit(train_X, train_y)\npred = np.exp(model.predict(test_X))\nactual = np.exp(test_y)\n\nactual = np.log(actual)\npredicted = np.log(pred)\nerror1 = np.sqrt(np.sum(np.square(actual-predicted))/len(actual))\nx.append(error1)\n\npred1 = np.exp(model.predict(train_X))\nactual1 = np.exp(train_y)\n\nactual1 = np.log(actual1)\npredicted1 = np.log(pred1)\nerror2 = np.sqrt(np.sum(np.square(actual1-predicted1))/len(actual1))\ny.append(error2)\n\nprint('TRAIN DATA\\n','Median:',np.median(y),'Max:',np.max(y),'Min:',np.min(y))\nprint('TEST DATA\\n','Median:',np.median(x),'Max:',np.max(x),'Min:',np.min(x))\nprint('Difference between sets:',np.median(x)-np.median(y))\n# # a = pd.DataFrame({'alpha':[i],'error':[err]})\n# # error = pd.concat([error, a],axis=0)\n\n# # fig, axarr = plt.subplots(figsize=(15,7))\n# # error.plot.scatter(x = 'alpha', y = 'error',ax=axarr)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1347a34a1b25e7c61718382a28a20dc79689028d"
      },
      "cell_type": "code",
      "source": "a = train_test.drop(scores.index[:120],axis=1)\na = a.drop('SalePrice',axis=1)\ntrain_test = train_test.drop(a,axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "27e8b06abd6890681c52ec351d4e3d596e465f35"
      },
      "cell_type": "code",
      "source": "# from sklearn.linear_model import Lasso\n# from xgboost import XGBRegressor\n\n# # for i in range(20):\n# #     train_X, test_X, train_y, test_y = train_test_split(train_test.drop(['SalePrice'],axis=1)[:1453],\\\n# #                                         np.log(train_test.SalePrice)[:1453],random_state=i)\n\n# model = Lasso(alpha=0.0001,tol=0.03)\n# model.fit(train_test[:1453].drop('SalePrice',axis=1), np.log(train_test.SalePrice[:1453]))\n# pred = np.exp(model.predict(train_test[1453:].drop('SalePrice',axis=1)))\n# # actual = np.exp(test_y)\n# test_set = pd.read_csv(r'../input/test.csv')\n# test_set = test_set.Id\n# test_set = pd.concat([test_set,pd.Series(pred)],axis=1)\n# test_set = test_set.rename(columns={0:'SalePrice'})\n# test_set = test_set.set_index('Id')\n# test_set.to_csv(r'submission.csv')\n\n# # actual = np.log(actual)\n# # predicted = np.log(pred)\n# # print(np.sqrt(np.sum(np.square(actual-predicted))/len(actual)))\n\n# # a = pd.DataFrame({'alpha':[i],'error':[err]})\n# # error = pd.concat([error, a],axis=0)\n\n# # fig, axarr = plt.subplots(figsize=(15,7))\n# # error.plot.scatter(x = 'alpha', y = 'error',ax=axarr)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "e77dcb564903c0ede6a14b069f4ba32adeb0405f"
      },
      "cell_type": "code",
      "source": "# from sklearn.linear_model import Lasso\n# from xgboost import XGBRegressor\n\n\n\n# error = pd.DataFrame({'CutoffVal':[],'error':[]})\n\n# for i in np.arange(0.001,0.01,0.0001):\n#     train_pyk = train_test.copy()\n#     for clean in train_pyk.columns:\n#         if len(train_pyk[(train_pyk[clean].isnull()) | (train_pyk[clean]==0)]) >= len(train_pyk)*(1-i):\n#             train_test = train_pyk.drop(clean, axis=1)\n\n    \n    \n#     train_X, test_X, train_y, test_y = train_test_split(train_pyk.drop('SalePrice',axis=1)[:1453],\\\n#                                     np.log(train_pyk.SalePrice)[:1453],random_state=1)\n\n    \n    \n#     model = Lasso(alpha = 0.00001, tol=0.1)\n#     model.fit(train_X, train_y)\n#     pred = np.exp(model.predict(test_X))\n#     actual = np.exp(test_y)\n\n#     actual = np.log(actual)\n#     predicted = np.log(pred)\n#     err = np.sqrt(np.sum(np.square(actual-predicted))/len(actual))\n#     a = pd.DataFrame({'CutoffVal':[i],'error':[err]})\n#     error = pd.concat([error, a],axis=0)\n\n# fig, axarr = plt.subplots(figsize=(15,7))\n# error.plot.scatter(x = 'CutoffVal', y = 'error',ax=axarr)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "308b9f4bdc899e2038a03deb5ea268f76065d77c"
      },
      "cell_type": "code",
      "source": "# train_set = train_test.loc[:1453]\n# correlation = train_set.corr(method='spearman').SalePrice.sort_values()\n# correlation = pd.DataFrame(correlation)\n# fig, axarr = matplotlib.pyplot.subplots(1,1,figsize=(70,320))\n# barplot = sns.barplot(data=correlation, y=correlation.index, x='SalePrice', orient='h')\n# barplot.tick_params(labelsize=60)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3e5322928ccf0af96fc9dacefd088fc79650ada1"
      },
      "cell_type": "code",
      "source": "# correlation\n\n# spike_cols = [correlation.loc[col] for col in correlation.index if 'GarageYrBlt' in col]\n\n# a = pd.DataFrame(spike_cols)\n# # fig, axarr = matplotlib.pyplot.subplots(1,1,figsize=(40,120))\n# # lol=sns.barplot(data=a, y='SalePrice', x=a.index, orient='h')\n# # lol.tick_params(labelsize=60)\n# a",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all",
      "text_representation": {
        "extension": ".py",
        "format_name": "light"
      }
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}